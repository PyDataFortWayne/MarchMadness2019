{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "The NCAA Basketball tournament is a time honored tradition that happens every March. Every year it earns it's nickname \"March Madness\" because of the upsets and the disappointments of people all around the world attempting to predict which team will win it all.\n",
    "\n",
    "With this projects we're attempting to leverage the NCAA data and data science / machine learning to do just that, predict the tournament champion.\n",
    "\n",
    "This Kaggle competition is scored based on the log-loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss\n",
    "Log-Loss is defined as $$-\\frac{1}{n}\\sum_{i=1}^n[y_{i}\\log(y_{\\hat{i}})+(1-y)\\log(1-y_{\\hat{i}})$$\n",
    "\n",
    "* n is the number of games played\n",
    "* $y_{\\hat{i}}$ is the predicted probability of team1 beating team2\n",
    "* $y_{i}$ is 1 if team1 wins, otherwise 0 if team2 wins\n",
    "* $\\log()$ is the natural (base e) logarithm\n",
    "\n",
    "The use of the logarithm provides extreme punishments for being both confident and wrong. In the worst possible case, a prediction that something is true when it is actually false will add an infinite amount to your error score. In order to prevent this, predictions are bounded away from the extremes by a small value.\n",
    "\n",
    "For reference a coin flip (50/50) would give us a log-loss ratio of just over 0.69. Our goal is to get under this number and get it as close to 0 as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "r = [i/N for i in range(1,N)]\n",
    "t = [1-ri for ri in r]\n",
    "f = [ri for ri in r]\n",
    "\n",
    "tll = [log_loss([0], list(zip([1-ri], [ri])), labels=[0, 1]) for ri in r]\n",
    "fll = [log_loss([0], list(zip([ri], [1-ri])), labels=[0, 1]) for ri in r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph helps illustrate how log-loss works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tll, label='Actual Value: 0')\n",
    "ax.plot(fll, label='Actual Value: 1')\n",
    "ax.axvline(N/2, color='k', linestyle='--', label='Coin Flip')\n",
    "plt.title('Log-Loss Values')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Log Loss Score')\n",
    "plt.legend()\n",
    "xtl = [xt/N for xt in ax.get_xticks().tolist()]\n",
    "ax.set_xticklabels(xtl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "- In the interest of time and simplicity we will ignore the players and events as part of this year's model. It could be expanded on at a later time to enchance the model with this additional data.\n",
    "- Seeds will not be used as they are a biased ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Kaggle & Google kindly supply us with data surrounding the teams, their stats and coaches each year. We are leveraging that data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(os.path.join(data_dir, 'Teams.csv'))\n",
    "df_teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to engineer our first additional feature by calculating the number of seasons the school has been in the D1 conference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams['D1Seasons'] = df_teams['LastD1Season'] - df_teams['FirstD1Season']\n",
    "teams_dict = df_teams[['TeamID', 'TeamName']].to_dict()\n",
    "del df_teams['TeamName']\n",
    "df_teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Game Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed = pd.read_csv(os.path.join(data_dir, 'Prelim2019_RegularSeasonDetailedResults.csv'))\n",
    "df_detailed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the difference in score which is a slightly better metric because if a team consistently scores 80+ points but allows their opponent to score 80+ points it's not as resounding a win or loss as if the opposing team scored only 40 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed['ScoreDiff'] = df_detailed['WScore'] - df_detailed['LScore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pull only the winning team columns and adding 1 to the W(in) colums and 0 to the L(oss) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['WLoc']\n",
    "include_cols = ['DayNum', 'Season']\n",
    "w_cols = [c for c in df_detailed \n",
    "          if (c.startswith('W') and c not in ignore_cols) or \n",
    "              c in include_cols]\n",
    "df_stats_W = df_detailed.loc[:, w_cols]\n",
    "c_names = {c:(c[1:] if c not in include_cols else c) for c in df_stats_W}\n",
    "df_stats_W.rename(columns=c_names, inplace=True)\n",
    "df_stats_W['W'] = 1\n",
    "df_stats_W['L'] = 0\n",
    "df_stats_W.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing for all of the losses. This allows us to track a team's record throughout the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['WLoc']\n",
    "include_cols = ['DayNum', 'Season']\n",
    "cols = [c for c in df_detailed if (c.startswith('L') and c not in ignore_cols) or c in include_cols]\n",
    "df_stats_L = df_detailed.loc[:, cols]\n",
    "c_names = {c:(c[1:] if c not in include_cols else c) for c in df_stats_L}\n",
    "df_stats_L.rename(columns=c_names, inplace=True)\n",
    "df_stats_L['W'] = 0\n",
    "df_stats_L['L'] = 1\n",
    "df_stats_L.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine all of the wins and losses together so we have one data source for a team's record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats_W.append(df_stats_L)\n",
    "df_stats = df_stats.sort_values(by=['TeamID', 'Season', 'DayNum'])\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're engineering another feature here for the game number. This will allow us to track a teams game average stats as the season progresses. (Group by and then run the cumulative sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_c_stats = df_stats.groupby(['TeamID', 'Season', 'DayNum']).sum().groupby(level=[0, 1]).cumsum()\n",
    "df_c_stats.reset_index(inplace=True)\n",
    "df_c_stats['GameNum'] = df_c_stats.reset_index().groupby(['TeamID', 'Season']).cumcount() + 1\n",
    "df_c_stats.set_index(['TeamID', 'Season'], inplace=True)\n",
    "df_c_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the percentages and per game stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_stats['FG_PCT'] = df_c_stats['FGM'] / df_c_stats['FGA']\n",
    "df_c_stats['FG3_PCT'] = df_c_stats['FGM3'] / df_c_stats['FGA3']\n",
    "df_c_stats['FT_PCT'] = df_c_stats['FTM'] / df_c_stats['FTA']\n",
    "\n",
    "PGL = ['Score', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "for pg in PGL:\n",
    "    df_c_stats[f'{pg}_PG'] = df_c_stats[pg] / df_c_stats['GameNum']\n",
    "df_c_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Team1 v Team2 is the same as Team2 v Team1 the Kaggle competition requires the lower team ID be team1 and the higher ID team be team2 for predition purposes. The predition is that Team1 will beat Team2.\n",
    "\n",
    "Here we're putting the prediction (outcome variable) in a format of 1 or 0 for the model to best utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_detailed.loc[:, ['Season', 'DayNum', 'WTeamID', 'LTeamID']]\n",
    "df_result['TeamID1'] = df_result.apply(lambda row: sorted([row['WTeamID'], row['LTeamID']])[0], axis=1)\n",
    "df_result['TeamID2'] = df_result.apply(lambda row: sorted([row['WTeamID'], row['LTeamID']])[1], axis=1)\n",
    "df_result['Pred'] = df_result['TeamID1'] == df_result['WTeamID']\n",
    "df_result['Pred'] = df_result['Pred'].astype(float)\n",
    "del df_result['WTeamID']\n",
    "del df_result['LTeamID']\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches\n",
    "We had access to coaching information which we thought would be useful as there are well known coaches who have been around for a long time and win a lot (which makes sense, they get paid to win). However after writing this section and adding the coaches to the model it actually caused the model to perform worse so it was taken out of the final model. It's been left in for historical purposes.\n",
    "\n",
    "This is likely because the resulting feature set was so sparse from all of the one hot encoding that was performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches = pd.read_csv(os.path.join(data_dir, 'Prelim2019_TeamCoaches.csv'))\n",
    "df_coaches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which iteration the coach as been with the team\n",
    "# Team A -> Team B -> Team A = 1 -> 2 -> 3\n",
    "\n",
    "df_coaches = df_coaches.sort_values(by=['CoachName', 'Season'])\n",
    "df_coaches['TeamNumber'] = df_coaches['TeamID'].ne(df_coaches['TeamID'].shift().bfill()).astype(int)\n",
    "df_coaches['TeamNumber'] = df_coaches.groupby(['CoachName'])['TeamNumber'].cumsum()\n",
    "df_coaches.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle special scenario where some coaches start with team number 0 instead of 1\n",
    "\n",
    "team_number_0_coaches = df_coaches[df_coaches['TeamNumber']==0]['CoachName'].unique()\n",
    "row_filter = df_coaches['CoachName'].isin(team_number_0_coaches)\n",
    "df_coaches.loc[row_filter, 'TeamNumber'] = df_coaches.loc[row_filter, 'TeamNumber'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the game identifier\n",
    "# This is required for the submission file\n",
    "def calc_gameid(row):\n",
    "    min_id = min(row['TeamID1'], row['TeamID2'])\n",
    "    max_id = max(row['TeamID1'], row['TeamID2'])\n",
    "    season = row['Season']\n",
    "    return f'{int(season)}_{int(min_id)}_{int(max_id)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_pg = df_c_stats.loc[:, ['W', 'L', 'GameNum', 'DayNum', 'FG_PCT',\n",
    "       'FG3_PCT', 'FT_PCT', 'Score_PG', 'OR_PG', 'DR_PG', 'Ast_PG', 'TO_PG',\n",
    "       'Stl_PG', 'Blk_PG', 'PF_PG']]\n",
    "\n",
    "mask = (df_c_pg['GameNum'] == 1)\n",
    "df0_i = df_c_pg[mask].copy().index\n",
    "df0 = pd.DataFrame(columns=df_c_pg.columns, index=df0_i)\n",
    "df0 = df0.fillna(0)\n",
    "df_c = df_c_pg.append(df0).reset_index()\n",
    "df_c.head()\n",
    "\n",
    "df_c_pg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to shift certain data elements because currently it's tracking statistics with the current game included. When we predict a game in the future we won't know the stats for the game that hasn't been played yet. To remedy this we shift the data down to the next row so that the statistics stored are actually up to date for the start of the game rather than the end of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift_col in ['W', 'L', 'FG_PCT',\n",
    "       'FG3_PCT', 'FT_PCT', 'Score_PG', 'OR_PG', 'DR_PG', 'Ast_PG', 'TO_PG',\n",
    "       'Stl_PG', 'Blk_PG', 'PF_PG']:\n",
    "    #df_c_pg[shift_col] = df_c_pg[shift_col].shift(1)\n",
    "    df_c_pg[shift_col] = df_c_pg.groupby(level=[0,1])[shift_col].shift(1)\n",
    "\n",
    "df_c_pg = df_c_pg.dropna()\n",
    "df_c_pg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_pg_coaches = pd.merge(\n",
    "    left = df_c_pg.reset_index(),\n",
    "    right = df_coaches,\n",
    "    on = ['TeamID', 'Season']\n",
    ")\n",
    "\n",
    "# Filter out coaches based on the game day to handle coaches who are replaced mid-season\n",
    "mask = (df_c_pg_coaches['FirstDayNum'] <= df_c_pg_coaches['DayNum'])\n",
    "mask = mask & (df_c_pg_coaches['LastDayNum'] >= df_c_pg_coaches['DayNum'])\n",
    "df_c_pg_coaches = df_c_pg_coaches[mask]\n",
    "df_c_pg_coaches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of seasons the coach has been coaching\n",
    "\n",
    "df_c_pg_coaches['SeasonsCoaching'] = df_c_pg_coaches['Season'] - df_c_pg_coaches.groupby('CoachName')['Season'].transform('min')\n",
    "del df_c_pg_coaches['FirstDayNum']\n",
    "del df_c_pg_coaches['LastDayNum']\n",
    "df_c_pg_coaches.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the coach names\n",
    "one_hot = pd.get_dummies(df_c_pg_coaches['CoachName'])\n",
    "df_c_pg_coaches = df_c_pg_coaches.drop('CoachName', axis=1)\n",
    "df_c_pg_coaches = df_c_pg_coaches.join(one_hot)\n",
    "df_c_pg_coaches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the statistics with all of the games being played for both the winning and losing teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_team1_details = pd.merge(\n",
    "    left = df_c_pg, #df_c_pg_coaches,\n",
    "    right = df_result,\n",
    "    left_index = False,\n",
    "    left_on = ['Season', 'DayNum', 'TeamID'],\n",
    "    right_index = False,\n",
    "    right_on = ['Season', 'DayNum', 'TeamID1']\n",
    ")\n",
    "df_result_team1_details.head()\n",
    "\n",
    "df_result_team_details = pd.merge(\n",
    "    left = df_c_pg, #df_c_pg_coaches,\n",
    "    right = df_result_team1_details,\n",
    "    left_index = False,\n",
    "    left_on = ['Season', 'DayNum', 'TeamID'],\n",
    "    right_index = False,\n",
    "    right_on = ['Season', 'DayNum', 'TeamID2'],\n",
    "    suffixes = ('_Team1', '_Team2')\n",
    ")\n",
    "\n",
    "df_result_team_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [c for c in df_result_team_details if c not in ['TeamID1', 'TeamID2', 'DayNum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model we only wanted to look at the 2019 data since college teams tend to have high turn over.\n",
    "\n",
    "We're also scaling the data to make sure everything is on the same scale since the number of points per game will typically be much higher than the number of turnovers or assists per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_result_team_details.copy()\n",
    "X = df_result_team_details[columns]\n",
    "X = X[X['Season']==2019]\n",
    "y = X.pop('Pred')\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "p = lr.predict_proba(X_test).clip(0.0000001, 0.99999999)\n",
    "print('Log Loss:', log_loss(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "c = [x / 1000.0 for x in range(1, 1000, 1)]\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = param_grid = {'C': c, 'solver':['lbfgs'], 'max_iter':[100000]}\n",
    "\n",
    "# run randomized search\n",
    "clf = GridSearchCV(lr, param_grid, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "p = lr.predict_proba(X_test).clip(0.0000001, 0.99999999)\n",
    "print('Log Loss:', log_loss(y_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_team_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to utilize data from mid-season so here we're filtering to pull the last game from the season for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_c_pg.reset_index()\n",
    "idx = df_t.groupby(['TeamID', 'Season'])['GameNum'].idxmax()\n",
    "df_t = df_t.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only compare teams in the tournament this year\n",
    "df_tourney_seeds = pd.read_csv(os.path.join(data_dir, 'NCAATourneySeeds.csv'))\n",
    "df_tourney_seeds = df_tourney_seeds.loc[df_tourney_seeds['Season']==2019]\n",
    "df_tourney_teams = df_tourney_seeds[['TeamID']]\n",
    "\n",
    "df_t = pd.merge(\n",
    "    left = df_t[df_t['Season']==2019],\n",
    "    right = df_tourney_teams,\n",
    "\n",
    "    on = ['TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the DataFrame to itself to get all possible permutations\n",
    "df_t_r = pd.merge(\n",
    "    left = df_t, #df_c_pg_coaches,\n",
    "    right = df_t,\n",
    "    left_index = False,\n",
    "    on = ['Season'],\n",
    "    right_index = False,\n",
    "    suffixes = ('_Team1', '_Team2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and move it to the end to match the same format\n",
    "# that we used to train our model\n",
    "df_t_r['TeamID1'] = df_t_r['TeamID_Team1']\n",
    "df_t_r['TeamID2'] = df_t_r['TeamID_Team2']\n",
    "del df_t_r['TeamID_Team1']\n",
    "del df_t_r['TeamID_Team2']\n",
    "\n",
    "# Since we can have 123 v 321 and 321 v 123 which would be\n",
    "# the same just displayed differently and the competition\n",
    "# wants just the lower team ID as team 1 let's de-dupe\n",
    "df_t_r = df_t_r.loc[df_t_r['TeamID1'] < df_t_r['TeamID2'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_r['GameID'] = df_t_r.apply(lambda row: calc_gameid(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gids = df_t_r.pop('GameID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack\n",
    "df_t_r['Pred'] = None\n",
    "df_t_r = df_t_r[columns]\n",
    "del df_t_r['Pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_t_r\n",
    "X = scaler.fit_transform(X)\n",
    "p = lr.predict_proba(X).clip(0.0000001, 0.99999999)\n",
    "#print('Log Loss:', log_loss(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [prob[0] for prob in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({'ID':gids, 'Pred':pred})\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(os.path.join(data_dir, 'Teams.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seeds = pd.read_csv(os.path.join(data_dir, 'NCAATourneySeeds.csv'))\n",
    "df_slots = pd.read_csv(os.path.join(data_dir, 'NCAATourneySlots.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bracket = pd.concat([df_sub, df_sub['ID'].str.extract(r'(?P<Season>\\d+)_(?P<TeamID1>\\d+)_(?P<TeamID2>\\d+)', expand=True)], axis=1)\n",
    "df_bracket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sub.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bracket['TeamID1'] = df_bracket['TeamID1'].astype(int)\n",
    "df_bracket['TeamID2'] = df_bracket['TeamID2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to help fill out my bracket\n",
    "def get_winner(team1, team2):\n",
    "    print(team1, team2)\n",
    "    if team1 > team2:\n",
    "        t = team2\n",
    "        team2 = team1\n",
    "        team1 = t\n",
    "    print(team1, team2)\n",
    "    mask = df_bracket['TeamID1'] == team1\n",
    "    mask = mask & (df_bracket['TeamID2'] == team2)\n",
    "    pred = df_bracket.loc[mask, 'Pred'].values[0]\n",
    "    if pred < 0.5:\n",
    "        print(f'{team2} has a {(1-pred)*100}% chance of winning')\n",
    "    else:\n",
    "        print(f'{team1} has a {pred*100}% chance of winning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_winner(1397, 1211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "* [X] calculate team wins and losses rolling for the season\n",
    "  * Added Game 0 Values, just need to determine how to shift W/L columns down to show values coming into game\n",
    "* [X] calculate rolling detailed stats FG %, FT %, 3PT %\n",
    "  * [X] shift to be stats prior to game?\n",
    "  * How handle first game of season as shift will make all stats NaN? Ignore first game of season.\n",
    "* [X] DO NOT USE SCORE (We won't know it when predicting future games. We can use the season average score though)\n",
    "* [X] Fine tune coach tenure (first season games are all currently 154 but it should be 0, 7, 14, 21 etc)\n",
    "* [X] One hot encode coaches?\n",
    "* [X] Shift per group not over all dataframe\n",
    "* [X] Create Submission\n",
    "* [ ] Clean up notebook for presentation\n",
    "* * [X] Make note how adding coaches did worse because it was so sparse with OHE\n",
    "* * [X] Explain Log-Loss function\n",
    "* * * [X] Add Graph of Log-Loss with 50%/coin flip vertical line\n",
    "* * [ ] Compare to picking the higher ranked teams\n",
    "* * [ ] Compare to another bracket\n",
    "* [X] Get Final 2018 dataset and rerun with 2019 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas to improve the model next time:\n",
    "* Rather than use the actual stats use a difference between the teams\n",
    "* Utilize the play in tournament data\n",
    "* Automatically generate bracket"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
